{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = edict(\n",
    "    {\n",
    "        \"data_path\": \"/home/ma-user/work/flowers_photos\",\n",
    "        \"data_size\": 3670,\n",
    "        \"image_width\": 100,  # 图片宽度\n",
    "        \"image_height\": 100,  # 图片高度\n",
    "        \"batch_size\": 32,\n",
    "        \"channel\": 3,  # 图片通道数\n",
    "        \"num_class\": 5,  # 分类类别\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr\": 0.0001,  # 学习率\n",
    "        \"dropout_ratio\": 0.5,\n",
    "        \"epoch_size\": 400,  # 训练次数\n",
    "        \"sigma\": 0.01,\n",
    "        \"save_checkpoint_steps\": 1,  # 多少步保存一次模型\n",
    "        \"keep_checkpoint_max\": 1,  # 最多保存多少个模型\n",
    "        \"output_directory\": \"./\",  # 保存模型路径\n",
    "        \"output_prefix\": \"checkpoint_classification\",  # 保存模型文件名字\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从目录中读取图像的源数据集。\n",
    "de_dataset = ds.ImageFolderDataset(\n",
    "    cfg.data_path,\n",
    "    class_indexing={\n",
    "        \"daisy\": 0,\n",
    "        \"dandelion\": 1,\n",
    "        \"roses\": 2,\n",
    "        \"sunflowers\": 3,\n",
    "        \"tulips\": 4,\n",
    "    },\n",
    ")\n",
    "# 解码前将输入图像裁剪成任意大小和宽高比。\n",
    "transform_img = CV.RandomCropDecodeResize(\n",
    "    [cfg.image_width, cfg.image_height], scale=(0.08, 1.0), ratio=(0.75, 1.333)\n",
    ")  # 改变尺寸\n",
    "# 转换输入图像；形状（H, W, C）为形状（C, H, W）。\n",
    "hwc2chw_op = CV.HWC2CHW()\n",
    "# 转换为给定MindSpore数据类型的Tensor操作。\n",
    "type_cast_op = C.TypeCast(mstype.float32)\n",
    "# 将操作中的每个操作应用到此数据集。\n",
    "de_dataset = de_dataset.map(\n",
    "    input_columns=\"image\", num_parallel_workers=8, operations=transform_img\n",
    ")\n",
    "de_dataset = de_dataset.map(\n",
    "    input_columns=\"image\", operations=hwc2chw_op, num_parallel_workers=8\n",
    ")\n",
    "de_dataset = de_dataset.map(\n",
    "    input_columns=\"image\", operations=type_cast_op, num_parallel_workers=8\n",
    ")\n",
    "de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)\n",
    "# 划分训练集测试集\n",
    "(de_train, de_test) = de_dataset.split([0.8, 0.2])\n",
    "# 设置每个批处理的行数\n",
    "# drop_remainder确定是否删除最后一个可能不完整的批（default=False）。\n",
    "# 如果为True，并且如果可用于生成最后一个批的batch_size行小于batch_size行，则这些行将被删除，并且不会传播到子节点。\n",
    "de_train = de_train.batch(cfg.batch_size, drop_remainder=True)\n",
    "# 重复此数据集计数次数。\n",
    "de_test = de_test.batch(cfg.batch_size, drop_remainder=True)\n",
    "print(\n",
    "    \"训练数据集数量：\", de_train.get_dataset_size() * cfg.batch_size\n",
    ")  # get_dataset_size()获取批处理的大小。\n",
    "print(\"测试数据集数量：\", de_test.get_dataset_size() * cfg.batch_size)\n",
    "# __next__方法处理后，获取一个batch的数据，数据格式为NCHW，第一维度为batch的数量。\n",
    "data_next = de_dataset.create_dict_iterator(output_numpy=True).__next__()\n",
    "print(\"通道数/图像长/宽：\", data_next[\"image\"].shape)\n",
    "print(\"一张图像的标签样式：\", data_next[\"label\"])  # 一共5类，用0-4的数字表达类别。\n",
    "print(data_next[\"image\"][0, ...].shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(data_next[\"image\"][1, ...])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN图像识别网络\n",
    "class Identification_Net(nn.Cell):\n",
    "    def __init__(\n",
    "        self, num_class=5, channel=3, dropout_ratio=0.5, trun_sigma=0.01\n",
    "    ):  # 一共分五类，图片通道数是3\n",
    "        super(Identification_Net, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.channel = channel\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        # 设置卷积层\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            self.channel,\n",
    "            32,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            has_bias=True,\n",
    "            pad_mode=\"same\",\n",
    "            weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "            bias_init=\"zeros\",\n",
    "        )\n",
    "        # 设置ReLU激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "        # 设置最大池化层\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            32,\n",
    "            64,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            has_bias=True,\n",
    "            pad_mode=\"same\",\n",
    "            weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "            bias_init=\"zeros\",\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            64,\n",
    "            128,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            has_bias=True,\n",
    "            pad_mode=\"same\",\n",
    "            weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "            bias_init=\"zeros\",\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            128,\n",
    "            128,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            has_bias=True,\n",
    "            pad_mode=\"same\",\n",
    "            weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "            bias_init=\"zeros\",\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(\n",
    "            6 * 6 * 128,\n",
    "            1024,\n",
    "            weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "            bias_init=0.1,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(self.dropout_ratio)\n",
    "        self.fc2 = nn.Dense(\n",
    "            1024, 512, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1\n",
    "        )\n",
    "        self.fc3 = nn.Dense(\n",
    "            512,\n",
    "            self.num_class,\n",
    "            weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "            bias_init=0.1,\n",
    "        )\n",
    "\n",
    "    # 构建模型\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化网络\n",
    "net = Identification_Net(\n",
    "    num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_ratio\n",
    ")\n",
    "# 计算softmax交叉熵，以此作为损失函数\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "# 获取网络中需要更新的参数\n",
    "fc_weight_params = list(\n",
    "    filter(lambda x: \"fc\" in x.name and \"weight\" in x.name, net.trainable_params())\n",
    ")\n",
    "other_params = list(\n",
    "    filter(\n",
    "        lambda x: \"fc\" not in x.name or \"weight\" not in x.name, net.trainable_params()\n",
    "    )\n",
    ")\n",
    "group_params = [\n",
    "    {\"params\": fc_weight_params, \"weight_decay\": cfg.weight_decay},\n",
    "    {\"params\": other_params},\n",
    "    {\"order_params\": net.trainable_params()},\n",
    "]\n",
    "# 设置Adam优化器，将前一步设定的需要更新的参数传入\n",
    "net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=0.0)\n",
    "# net_opt = nn.Adam(params=net.trainable_params(), learning_rate=cfg.lr, weight_decay=0.1)\n",
    "# 编译网络、损失函数和优化器\n",
    "model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics={\"acc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定callback监控指标\n",
    "loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size() * 10)\n",
    "config_ck = CheckpointConfig(\n",
    "    save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "    keep_checkpoint_max=cfg.keep_checkpoint_max,\n",
    ")\n",
    "ckpoint_cb = ModelCheckpoint(\n",
    "    prefix=cfg.output_prefix, directory=cfg.output_directory, config=config_ck\n",
    ")\n",
    "print(\"============== Starting Training ==============\")\n",
    "# 开始训练，训练时将callback监控指标设定好\n",
    "model.train(\n",
    "    cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=True\n",
    ")\n",
    "\n",
    "# 使用测试集评估模型，打印总体准确率\n",
    "metric = model.eval(de_test)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "import os\n",
    "\n",
    "# 获取路径\n",
    "CKPT = os.path.join(\n",
    "    cfg.output_directory,\n",
    "    cfg.output_prefix\n",
    "    + \"-\"\n",
    "    + str(cfg.epoch_size)\n",
    "    + \"_\"\n",
    "    + str(de_train.get_dataset_size())\n",
    "    + \".ckpt\",\n",
    ")\n",
    "# 实例化网络\n",
    "net = Identification_Net(\n",
    "    num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_ratio\n",
    ")\n",
    "# 将参数加载进网络\n",
    "load_checkpoint(CKPT, net=net)\n",
    "# 编译整个模型\n",
    "model = Model(net)\n",
    "# 预测\n",
    "class_names = {0: \"daisy\", 1: \"dandelion\", 2: \"roses\", 3: \"sunflowers\", 4: \"tulips\"}\n",
    "# 获取测试集的batch\n",
    "test_ = de_test.create_dict_iterator().__next__()\n",
    "# 转换为tensor\n",
    "test = Tensor(test_[\"image\"], mindspore.float32)\n",
    "# 预测\n",
    "predictions = model.predict(test)\n",
    "predictions = predictions.asnumpy()\n",
    "true_label = test_[\"label\"].asnumpy()\n",
    "\n",
    "# 显示预测结果\n",
    "for i in range(9):\n",
    "    p_np = predictions[i, :]\n",
    "    pre_label = np.argmax(p_np)\n",
    "    print(\n",
    "        \"第\" + str(i) + \"个sample预测结果：\",\n",
    "        class_names[pre_label],\n",
    "        \"真实结果：\",\n",
    "        class_names[true_label[i]],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
